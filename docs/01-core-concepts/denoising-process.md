[🏠 홈](../../README.md) | [📚 전체 목차](../../README.md#-전체-문서-목차)

---

# Denoising Process - 이미지 생성의 핵심

> AI가 노이즈에서 이미지를 만들어내는 전체 과정

[🏠 홈](../../README.md) | [📚 전체 목차](../../docs/README.md)

---

## 🎯 가이드 개요

**대상 독자:** AI가 그림을 그리는 구체적인 단계가 궁금한 사용자
**사전 이해:** Latent Image 개념 (Part 1 또는 핵심 개념 참조)
**예상 소요 시간:** 20분

**핵심 내용:**
- 왜 노이즈를 추가했다가 다시 제거하는지 이유 (학습 원리)
- KSampler가 노이즈를 걷어내며 그림을 완성하는 과정
- U-Net, Scheduler, Text Encoder가 협업하는 방식

---

## 📑 목차

1. [왜 노이즈를 추가했다가 제거하나?](#1-왜-노이즈를-추가했다가-제거하나)
2. [Diffusion 모델의 기본 원리](#2-diffusion-모델의-기본-원리)
3. [U-Net의 역할](#3-u-net의-역할)
4. [Scheduler의 역할](#4-scheduler의-역할)
5. [텍스트 컨디셔닝](#5-텍스트-컨디셔닝)
6. [전체 파이프라인](#6-전체-파이프라인)

---

## 1. 왜 노이즈를 추가했다가 제거하나?

### 🎯 핵심 질문

**"원본 이미지에 노이즈를 섞는 이유는?"**

→ **모델이 단계별로 복원하는 법을 학습하도록 하기 위함**

### 📊 학습 과제 정의

```
모델에게 주어지는 질문:
"이 정도 노이즈가 섞인 상태에서 원본이 어떤 모습이었을까?"
```

**반복 학습:**
```
Step 1000: 완전 노이즈 → 원본 예측
Step 999:  99.9% 노이즈 → 원본 예측
Step 998:  99.8% 노이즈 → 원본 예측
...
Step 1:    0.1% 노이즈 → 원본 예측
```

### 💡 왜 작은 단계로 나누나?

**문제:** 완전 노이즈 → 깨끗한 이미지 (한 번에)
```
❌ 너무 어려움
   예측 불가능
```

**해결:** 아주 작은 노이즈 증감 (1000단계)
```
✅ 작은 변화는 예측 가능
   단계별로 차근차근 학습
```

### 🔍 확률 분포 관점

**핵심 개념:**

| 단계 | 분포 | 의미 |
|------|------|------|
| **노이즈 분포** | N(0,1) | 완전 랜덤 |
| **원본 분포** | 자연스러운 이미지 | 의미 있는 픽셀 배열 |
| **학습 목표** | 노이즈 → 원본 매핑 | 확률적 이해 |

---

## 2. Diffusion 모델의 기본 원리

### 🎯 Diffusion이란?

**Diffusion = 확산 (퍼져나감)**

물감 한 방울이 물에 퍼지듯, 노이즈가 이미지에 서서히 퍼집니다.

### 📊 Forward vs Reverse Process

#### Forward Process (학습 데이터 생성)

```
깨끗한 이미지 (x₀)
    ↓ +작은 노이즈
  99% 깨끗 (x₁)
    ↓ +작은 노이즈
  98% 깨끗 (x₂)
    ↓ ... (1000 steps)
완전 노이즈 (x₁₀₀₀)
```

**목적:** 학습용 노이즈 데이터 생성

#### Reverse Process (이미지 생성)

```
완전 노이즈 (x₁₀₀₀)
    ↓ -노이즈 예측 제거
  1% 깨끗 (x₉₉₉)
    ↓ -노이즈 예측 제거
  2% 깨끗 (x₉₉₈)
    ↓ ... (1000 steps)
깨끗한 이미지 (x₀)
```

**목적:** 실제 이미지 생성

### 💡 계단 비유

```
Diffusion 모델 = 1000개 계단을 내려가는 과정

완전 노이즈 (1000층)
    ↓ 한 계단씩
    ↓ 노이즈 조금씩 제거
    ↓ 이미지 점점 선명
깨끗한 이미지 (1층)
```

---

## 3. U-Net의 역할

### 🎯 U-Net이란?

**U-Net = 노이즈를 예측하는 전문가**

매 단계마다 "지금 이 latent에 섞여 있는 노이즈가 얼마인가?"를 예측합니다.

### 📊 U-Net 입력과 출력

| 입력 | 출력 | 의미 |
|------|------|------|
| **Noisy Latent (xₜ)** | **Noise Prediction (ε)** | 이 노이즈를 제거하면 됨 |
| **Timestep (t)** | - | 현재 몇 번째 단계인지 |
| **Text Embedding** | - | 어떤 이미지를 만들지 |

### 🔄 U-Net 구조

```
      Input: Noisy Latent (128×128×16)
             │
        ┌────▼────┐
        │ Encoder │  압축 (디테일 → 핵심)
        └────┬────┘
             │
        ┌────▼────┐
        │ Bottleneck │ ← 가장 압축된 상태
        └────┬────┘
             │
        ┌────▼────┐
        │ Decoder │  복원 (핵심 → 디테일)
        └────┬────┘
             │
      Output: Noise Prediction
```

**Skip Connection:**
```
Encoder의 각 레이어
    ↓ (복사)
Decoder의 대응 레이어
```

**역할:** 전체 구조 + 세부 디테일 동시에 다룸

### 💡 왜 U자 모양?

```
Input (큼)
    ↓ 압축
작아짐...
    ↓ 최소
Bottleneck (작음) ← 핵심 정보만
    ↑ 복원
커짐...
    ↑ 확장
Output (큼)

"U" 모양!
```

---

## 4. Scheduler의 역할

### 🎯 Scheduler란?

**Scheduler = 각 단계에서 노이즈 강도를 관리하는 관리자**

U-Net이 예측한 노이즈를 어떻게 제거할지 결정합니다.

### 📊 Scheduler의 작동

```
현재 Latent (xₜ)
    ↓
U-Net → Noise Prediction (ε)
    ↓
Scheduler: 이 노이즈를 얼마나 제거할까?
    ↓
다음 Latent (xₜ₋₁)
```

### 🔄 Scheduler 종류

| Scheduler | 방식 | 특징 |
|-----------|------|------|
| **DDPM** | 천천히 조금씩 | 안정적, 느림 |
| **DDIM** | 큰 스텝으로 | 빠름, 결정적 |
| **Euler** | 1차 미분 | 단순, 빠름 |
| **DPM** | 2차 미분 | 정확, 느림 |

### 💡 제어력 (Strength)

**Image-to-Image 변형 시:**

```
strength = 0.0:  원본 그대로 (노이즈 0%)
strength = 0.5:  절반 변형 (노이즈 50%)
strength = 1.0:  완전 새로 생성 (노이즈 100%)
```

**활용:**
```
원본 보존 vs 새로 생성의 균형 조절
```

---

## 5. 텍스트 컨디셔닝

### 🎯 컨디셔닝이란?

**Conditioning = 생성 방향을 지정하는 것**

텍스트가 "어떤 이미지"를 만들지 방향을 잡아줍니다.

### 📊 CLIP Text Encoder의 역할

```
Text Prompt: "a red sports car on a desert road"
    ↓
CLIP Text Encoder
    ↓
Text Embedding (고차원 벡터)
    ↓
U-Net에 전달 (컨디셔닝)
```

**임베딩 내용:**
- "어떤 개념" (차, 사막)
- "어떤 스타일" (스포츠카)
- "어떤 구성" (차가 도로 위)

### 🔄 디노이징 과정에서의 컨디셔닝

```
U-Net 각 스텝마다:

입력:
- Noisy Latent (xₜ)
- Timestep (t)
- Text Embedding ← 컨디셔닝

처리:
Cross-Attention으로
"어떤 위치에 어떤 개념을 넣을까?" 계산

출력:
- Noise Prediction (텍스트 반영됨)
```

### 💡 Cross-Attention

**역할:** 텍스트와 이미지 위치 연결

```
Image Feature: 왼쪽 영역
    ↓ Attention
Text Token: "red car"
    ↓
왼쪽에 빨간 차 배치 ✅
```

### 🎯 어떻게 원하는 이미지를 얻는가?

**매 스텝마다:**

```
질문: "현재 noisy 상태에서 텍스트가 가리키는
       이미지로 가려면 어떤 노이즈 제거?"

답변: CLIP 텍스트 임베딩이 방향 제시
      ↓
   노이즈 제거 + 텍스트 정보 채우기
```

---

## 6. 전체 파이프라인

### 🔄 완전한 Text-to-Image 생성 흐름

```
┌─────────────────────────────────────┐
│ 1. 텍스트 입력                       │
│    "a cat wearing a hat"             │
└──────────────┬──────────────────────┘
               ↓
┌─────────────────────────────────────┐
│ 2. Text Encoder (CLIP)               │
│    텍스트 → Embedding                │
└──────────────┬──────────────────────┘
               ↓
┌─────────────────────────────────────┐
│ 3. 랜덤 노이즈 생성                  │
│    (128×128×16)                     │
└──────────────┬──────────────────────┘
               ↓
┌─────────────────────────────────────┐
│ 4. Denoising Loop (1000 steps)      │
│                                      │
│    ┌──────────────────────────┐    │
│    │ Step t:                  │    │
│    │   Input:  xₜ             │    │
│    │   U-Net → ε prediction   │    │
│    │   Scheduler → xₜ₋₁       │    │
│    └─────────┬────────────────┘    │
│              ↓                      │
│    반복... (t = 1000 → 0)          │
└──────────────┬──────────────────────┘
               ↓
┌─────────────────────────────────────┐
│ 5. Clean Latent                      │
│    (128×128×16)                     │
└──────────────┬──────────────────────┘
               ↓
┌─────────────────────────────────────┐
│ 6. VAE Decoder                       │
│    Latent → Image                    │
└──────────────┬──────────────────────┘
               ↓
┌─────────────────────────────────────┐
│ 7. 최종 이미지                       │
│    (1024×1024×3 RGB)                │
│    모자 쓴 고양이 🐱                 │
└─────────────────────────────────────┘
```

### 🎯 각 구성요소 역할 요약

| 구성요소 | 역할 | 비유 |
|----------|------|------|
| **Text Encoder** | 텍스트 → 의미 벡터 | GPS (목적지 설정) |
| **노이즈** | 시작점 + 다양성 | 랜덤 씨앗 |
| **U-Net** | 노이즈 예측 | 노이즈 탐지기 |
| **Scheduler** | 노이즈 제거 관리 | 단계별 실행자 |
| **VAE** | Latent ↔ Image | 압축/복원 도구 |

### 💡 멘토링 포인트

**1. 임베딩 품질**
```
✅ 좋은 프롬프트 → 좋은 임베딩 → 좋은 결과
❌ 모호한 프롬프트 → 약한 가이드 → 불확실한 결과
```

**2. 어텐션 설계**
```
Cross-Attention 강도 = 텍스트 영향력
너무 강하면: 텍스트에 과도하게 집착
너무 약하면: 텍스트 무시
```

**3. 스케줄러 세팅**
```
Strength 조절 = 텍스트 vs 원본 이미지 균형
Image-to-Image 변형 시 중요
```

**4. 랜덤 시드**
```
같은 프롬프트, 다른 시드 → 다른 결과
재현성 필요 시 시드 고정
```

---

## 🎓 학습 정리

### 꼭 기억해야 할 것

1. **노이즈 추가 → 복원 학습**
   - 작은 단계로 나눠 학습
   - 확률 분포 매핑
   - 안정적 생성 가능

2. **U-Net**
   - 노이즈 예측 전문가
   - Skip Connection으로 구조+디테일
   - Cross-Attention으로 텍스트 반영

3. **Scheduler**
   - 노이즈 제거 관리자
   - 단계별 노이즈 강도 조절
   - Strength로 제어력 확보

4. **텍스트 컨디셔닝**
   - CLIP으로 텍스트 → 임베딩
   - Cross-Attention으로 위치 연결
   - 매 스텝마다 방향 제시

---

## 📚 다음 단계

**디노이징 이해 완료! 이제:**

1. [CLIP과 Contrastive Learning](./clip-contrastive-learning.md) - 텍스트 임베딩 심화
2. [Sampler 비교](../03-advanced-techniques/samplers/sampler-comparison.md) - Scheduler 종류
3. [Flux 모델](../02-models/flux/README.md) - 실전 활용

---

## 💡 복습 퀴즈

스스로 답해보세요:

1. 왜 노이즈를 추가했다가 제거하나요?
2. U-Net의 역할은 무엇인가요?
3. Scheduler는 무엇을 관리하나요?
4. 텍스트 컨디셔닝은 어떻게 작동하나요?

**답을 모르겠다면 해당 섹션을 다시 읽어보세요!**

---

**🎓 디노이징 프로세스 이해 완료!**

---

[🏠 홈으로](../../README.md) | [📖 핵심 개념](./README.md)
